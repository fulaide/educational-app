name: ⚡ Performance Monitoring

on:
  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  push:
    branches: [main]
    paths:
      - 'apps/**'
      - 'packages/ui/**'
  workflow_dispatch:
    inputs:
      apps:
        description: 'Apps to test (comma-separated or "all")'
        required: true
        default: 'all'
        type: string

concurrency:
  group: performance-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Lighthouse Performance Tests
  lighthouse-tests:
    name: 🏮 Lighthouse Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      matrix:
        app:
          - { name: 'student-app', port: 5173, url: 'http://localhost:5173' }
          - { name: 'teacher-portal', port: 5174, url: 'http://localhost:5174' }
          - { name: 'parent-portal', port: 5175, url: 'http://localhost:5175' }

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🏗 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci

      - name: 🚀 Start ${{ matrix.app.name }}
        run: |
          npm run dev --filter=${{ matrix.app.name }} &
          sleep 30
          curl --retry 10 --retry-delay 5 --retry-connrefused ${{ matrix.app.url }} || exit 1

      - name: 🏮 Run Lighthouse tests
        run: |
          npm install -g @lhci/cli@0.12.x
          
          # Create LHCI configuration
          cat > .lighthouserc.json << EOF
          {
            "ci": {
              "collect": {
                "url": ["${{ matrix.app.url }}"],
                "numberOfRuns": 3,
                "settings": {
                  "chromeFlags": ["--no-sandbox", "--headless"]
                }
              },
              "assert": {
                "assertions": {
                  "categories:performance": ["error", {"minScore": 0.7}],
                  "categories:accessibility": ["error", {"minScore": 0.9}],
                  "categories:best-practices": ["error", {"minScore": 0.8}],
                  "categories:seo": ["error", {"minScore": 0.8}],
                  "categories:pwa": ["warn", {"minScore": 0.6}]
                }
              },
              "upload": {
                "target": "temporary-public-storage"
              }
            }
          }
          EOF
          
          lhci autorun --config=.lighthouserc.json

      - name: 📊 Upload Lighthouse results
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-${{ matrix.app.name }}
          path: .lighthouseci/

  # Bundle Size Analysis
  bundle-analysis:
    name: 📦 Bundle Size Analysis
    runs-on: ubuntu-latest
    strategy:
      matrix:
        app: [student-app, teacher-portal, parent-portal, admin-dashboard]

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🏗 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci

      - name: 🏗 Build ${{ matrix.app }}
        run: npm run build --filter=${{ matrix.app }}

      - name: 📊 Analyze bundle size
        run: |
          cd apps/${{ matrix.app }}
          
          # Install bundle analyzer
          npm install --no-save webpack-bundle-analyzer
          
          # Create bundle analysis report
          echo "## 📦 Bundle Analysis for ${{ matrix.app }}" > bundle-report.md
          echo "" >> bundle-report.md
          
          # Get build folder size
          BUILD_SIZE=$(du -sh build/ 2>/dev/null | cut -f1 || echo "N/A")
          echo "**Total Build Size:** $BUILD_SIZE" >> bundle-report.md
          echo "" >> bundle-report.md
          
          # List largest files
          echo "### 🗂️ Largest Files:" >> bundle-report.md
          find build -name "*.js" -o -name "*.css" | xargs ls -lh | sort -k5 -hr | head -10 | \
          awk '{print "- **" $9 ":** " $5}' >> bundle-report.md || true
          
          echo "" >> bundle-report.md
          
          # Asset summary
          JS_SIZE=$(find build -name "*.js" -exec cat {} + | wc -c | awk '{print int($1/1024)"KB"}')
          CSS_SIZE=$(find build -name "*.css" -exec cat {} + | wc -c | awk '{print int($1/1024)"KB"}')
          
          echo "### 📈 Asset Summary:" >> bundle-report.md
          echo "- **JavaScript:** $JS_SIZE" >> bundle-report.md
          echo "- **CSS:** $CSS_SIZE" >> bundle-report.md

      - name: 📊 Upload bundle analysis
        uses: actions/upload-artifact@v4
        with:
          name: bundle-analysis-${{ matrix.app }}
          path: apps/${{ matrix.app }}/bundle-report.md

  # Load Testing
  load-testing:
    name: 🚛 Load Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🏗 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci

      - name: 🚀 Start applications
        run: |
          npm run dev:student &
          npm run dev:teacher &
          sleep 30

      - name: 🚛 Run load tests
        run: |
          # Install k6 for load testing
          curl -s https://api.github.com/repos/grafana/k6/releases/latest | \
          grep "browser_download_url.*linux-amd64.tar.gz" | \
          cut -d '"' -f 4 | \
          xargs curl -L | tar xz --strip-components=1
          chmod +x k6
          
          # Create load test script
          cat > loadtest.js << 'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          
          export let options = {
            stages: [
              { duration: '2m', target: 10 }, // Ramp up
              { duration: '5m', target: 50 }, // Stay at 50 users
              { duration: '2m', target: 0 },  // Ramp down
            ],
            thresholds: {
              http_req_duration: ['p(95)<500'], // 95% of requests under 500ms
              http_req_failed: ['rate<0.1'],   // Error rate under 10%
            },
          };
          
          const BASE_URLS = [
            'http://localhost:5173', // Student app
            'http://localhost:5174', // Teacher portal
          ];
          
          export default function() {
            const url = BASE_URLS[Math.floor(Math.random() * BASE_URLS.length)];
            const response = http.get(url);
            
            check(response, {
              'status is 200': (r) => r.status === 200,
              'response time < 500ms': (r) => r.timings.duration < 500,
            });
            
            sleep(1);
          }
          EOF
          
          # Run load test
          ./k6 run loadtest.js --out json=loadtest-results.json

      - name: 📊 Process load test results
        run: |
          echo "## 🚛 Load Test Results" > loadtest-report.md
          echo "" >> loadtest-report.md
          
          # Extract key metrics from results
          if [ -f loadtest-results.json ]; then
            echo "Load test completed successfully" >> loadtest-report.md
            echo "" >> loadtest-report.md
            
            # Add summary metrics (simplified - in production use proper JSON parsing)
            echo "### 📊 Key Metrics:" >> loadtest-report.md
            echo "- Test completed at $(date)" >> loadtest-report.md
            echo "- Virtual users: 50 peak" >> loadtest-report.md
            echo "- Duration: 9 minutes" >> loadtest-report.md
          else
            echo "⚠️ Load test failed to generate results" >> loadtest-report.md
          fi

      - name: 📊 Upload load test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: |
            loadtest-results.json
            loadtest-report.md

  # Mobile Performance Testing
  mobile-performance:
    name: 📱 Mobile Performance
    runs-on: ubuntu-latest

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🏗 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: 📦 Install dependencies
        run: npm ci

      - name: 🚀 Start student app
        run: |
          npm run dev:student &
          sleep 30

      - name: 📱 Mobile Lighthouse tests
        run: |
          npm install -g @lhci/cli@0.12.x
          
          cat > mobile-lighthouse.json << EOF
          {
            "ci": {
              "collect": {
                "url": ["http://localhost:5173"],
                "numberOfRuns": 3,
                "settings": {
                  "chromeFlags": ["--no-sandbox", "--headless"],
                  "emulatedFormFactor": "mobile",
                  "throttling": {
                    "rttMs": 150,
                    "throughputKbps": 1600,
                    "cpuSlowdownMultiplier": 4
                  }
                }
              },
              "assert": {
                "assertions": {
                  "categories:performance": ["error", {"minScore": 0.6}],
                  "categories:accessibility": ["error", {"minScore": 0.9}],
                  "largest-contentful-paint": ["error", {"maxNumericValue": 3000}],
                  "cumulative-layout-shift": ["error", {"maxNumericValue": 0.1}]
                }
              }
            }
          }
          EOF
          
          lhci autorun --config=mobile-lighthouse.json

      - name: 📊 Upload mobile performance results
        uses: actions/upload-artifact@v4
        with:
          name: mobile-performance
          path: .lighthouseci/

  # Generate Performance Report
  performance-report:
    name: 📊 Performance Report
    runs-on: ubuntu-latest
    needs: [lighthouse-tests, bundle-analysis, mobile-performance]
    if: always()

    steps:
      - name: 📥 Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: performance-results

      - name: 📊 Generate comprehensive report
        run: |
          echo "## ⚡ Performance Monitoring Report" > performance-report.md
          echo "" >> performance-report.md
          echo "**Date:** $(date)" >> performance-report.md
          echo "**Trigger:** ${{ github.event_name }}" >> performance-report.md
          echo "" >> performance-report.md
          
          echo "### 🏮 Lighthouse Results" >> performance-report.md
          echo "" >> performance-report.md
          
          # Process Lighthouse results
          for app in student-app teacher-portal parent-portal; do
            if [ -d "performance-results/lighthouse-$app" ]; then
              echo "#### $app" >> performance-report.md
              echo "- ✅ Lighthouse tests completed" >> performance-report.md
              echo "" >> performance-report.md
            fi
          done
          
          echo "### 📦 Bundle Analysis" >> performance-report.md
          echo "" >> performance-report.md
          
          # Include bundle reports
          for report in performance-results/bundle-analysis-*/bundle-report.md; do
            if [ -f "$report" ]; then
              cat "$report" >> performance-report.md
              echo "" >> performance-report.md
            fi
          done
          
          echo "### 📱 Mobile Performance" >> performance-report.md
          echo "" >> performance-report.md
          if [ -d "performance-results/mobile-performance" ]; then
            echo "- ✅ Mobile performance tests completed" >> performance-report.md
            echo "- 🎯 Focus on student app mobile experience" >> performance-report.md
          fi
          echo "" >> performance-report.md
          
          echo "### 🎯 Recommendations" >> performance-report.md
          echo "- Monitor Core Web Vitals for student engagement" >> performance-report.md
          echo "- Optimize mobile performance for primary users" >> performance-report.md
          echo "- Consider offline-first improvements" >> performance-report.md

      - name: 💬 Comment on PR (if applicable)
        if: github.event_name == 'push' && github.event.pull_request
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('performance-report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.payload.pull_request.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

      - name: 📊 Upload final report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: performance-report.md

      - name: 🔔 Notify team of performance issues
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              "text": "⚠️ Performance tests failed!",
              "attachments": [
                {
                  "color": "warning",
                  "text": "Performance monitoring detected issues in the educational app platform.",
                  "fields": [
                    {
                      "title": "Workflow",
                      "value": "Performance Monitoring",
                      "short": true
                    },
                    {
                      "title": "Trigger", 
                      "value": "${{ github.event_name }}",
                      "short": true
                    }
                  ],
                  "actions": [
                    {
                      "type": "button",
                      "text": "View Results",
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}